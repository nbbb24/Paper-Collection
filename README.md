# ðŸ“š Research Papers Collection

A curated collection of research papers I'm reading, have read, or plan to read.

## ðŸ“‘ Content by Topic

**Tools**

**Papers**
- [ðŸ§  Reasoning](#-reasoning)
- [ðŸ¤– Agent](#-agent)
- [ðŸ’¬ Large Language Model](#-large-language-model)
- [ðŸ“Š Physiological Signals](#-physiological-signals)
- [ðŸ”’ Privacy](#-privacy)
- [ðŸ”¬ Multimodal](#-multimodal)

**Knowledge Base**
- [ðŸ“– AI/ML Knowledge](#-aiml-knowledge)

**Courses**
- [Courses](#courses)

---
## Tools
- **[ComfyAI](https://comfyai.app/)** - Collection of LLM techniques and workflows
- **[verl](https://github.com/volcengine/verl)** - Volcano Engine Reinforcement Learning for LLMs (RLHF framework supporting FSDP, vLLM, SGLang)
- **[FeatureDB](https://github.com/PKUDigitalHealth/FeatureDB)** - Pattern recognition methods for ECG feature extraction (expert features including HRV, morphologic variability, frequency domain, QRS axis)
- **[HeartPy](https://github.com/paulvangentcom/heartrate_analysis_python)** - Python Heart Rate Analysis Toolkit for PPG and ECG signals (time-domain & frequency-domain measures)
- **[Braindecode](https://github.com/braindecode/braindecode)** - Deep learning toolbox for decoding EEG, ECG, and MEG signals (PyTorch-based, includes datasets, preprocessing, models)


## Papers and Blogs

### ðŸ§  Reasoning
- **[Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)** - John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov (2017)
- **[Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)** - Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan (2023)
- **[Understanding the Math Behind GRPO â€” DeepSeek-R1-Zero](https://medium.com/yugen-ai-technology-blog/understanding-the-math-behind-grpo-deepseek-r1-zero-9fb15e103a0a)** - Soumanta Das, Yugen.ai (2025)
- **[DeepSeek-V3 Explained 1: Multi-head Latent Attention](https://medium.com/data-science/deepseek-v3-explained-1-multi-head-latent-attention-ed6bee2a67c4)** - Shirley Li (2025)
- **[Mixture-of-Experts (MoE) LLMs](https://cameronrwolfe.substack.com/p/moe-llms)** - Cameron R. Wolfe (2025)
- **[DeepSeek-V3 â€” Advances in MoE Load Balancing and Multi-Token Prediction Training](https://medium.com/yugen-ai-technology-blog/deepseek-v3-advances-in-moe-load-balancing-and-multi-token-prediction-training-f6d68c59749c)** - Soumanta Das, Yugen.ai (2025)
- **[DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/abs/2402.03300)** - Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, et al. (2024)
- **[DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)** - DeepSeek-AI (2025)
- **[QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training](https://arxiv.org/abs/2506.00711)** - Wei Dai, Peilin Chen, Chanakya Ekbote, Paul Pu Liang (2025)
- **[MedCritical: Enhancing Medical Reasoning in Small Language Models via Self-Collaborative Correction](https://arxiv.org/abs/2509.23368)** - (2025)
- **[OpenTSLM: Time-Series Language Models for Reasoning over Multivariate Medical Text- and Time-Series Data](https://arxiv.org/abs/2510.02410)** - Patrick Langer, Thomas Kaar, Max Rosenblattl, Maxwell A. Xu, Winnie Chow, et al. (2025)

### ðŸ¤– Agent
- **[The Anatomy of a Personal Health Agent](https://arxiv.org/abs/2508.20148)** - A. Ali Heydari, Ken Gu, Vidya Srinivas, Hong Yu, et al. (2025)

### ðŸ’¬ Large Language Model
- **[Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer](https://arxiv.org/abs/1701.06538)** - Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, Jeff Dean (2017)
- **[Deep contextualized word representations (ELMo)](https://arxiv.org/abs/1802.05365)** - Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer (2018)
- **[LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)** - Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, et al. (2021)
- **[The Llama 3 Herd of Models](https://arxiv.org/abs/2407.21783)** - Meta AI (2024)
- **[Qwen2.5 Technical Report](https://arxiv.org/abs/2412.15115)** - Qwen Team, Alibaba (2024)

### ðŸ“Š Physiological Signals
- **[ENCASE: an ENsemble ClASsifiEr for ECG Classification Using Expert Features and Deep Neural Networks](https://www.cinc.org/archives/2017/pdf/178-245.pdf)** - Shenda Hong, Meng Wu, Yuxi Zhou, Qingyun Wang, Junyuan Shang, Hongyan Li, Junqing Xie (2017)
- **[ECG-QA: A Comprehensive Question Answering Dataset Combined With Electrocardiogram](https://arxiv.org/abs/2306.15681)** - Jungwoo Oh, Gyubok Lee, Seongsu Bae, Joon-myoung Kwon, Edward Choi (2023)
- **[Health-LLM: Large Language Models for Health Prediction via Wearable Sensor Data](https://arxiv.org/abs/2401.06866)** - Yubin Kim, Xuhai Xu, Daniel McDuff, Cynthia Breazeal, Hae Won Park (2024)
- **[A lightweight deep neural network for personalized detecting ventricular arrhythmias from a single-lead ECG device](https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0001037)** - Zhejun Sun, Wenrui Zhang, Yuxi Zhou, Shijia Geng, et al. (2025)
- **[ECG-Chat: A Large ECG-Language Model for Cardiac Disease Diagnosis](https://arxiv.org/abs/2408.08849)** - Yubao Zhao, Jiaju Kang, Tian Zhang, Puyu Han, Tong Chen (2024)
- **[ECG-Byte: A Tokenizer for End-to-End Generative Electrocardiogram Language Modeling](https://arxiv.org/abs/2412.14373)** - William Han, Chaojing Duan, Michael A. Rosenberg, Emerson Liu, Ding Zhao (2024)
- **[GEM: Empowering MLLM for Grounded ECG Understanding with Time Series and Images](https://arxiv.org/abs/2503.06073)** - Xiang Lan, Feng Wu, Kai He, Qinghao Zhao, Shenda Hong, Mengling Feng (2025)
- **[Signal, Image, or Symbolic: Exploring the Best Input Representation for Electrocardiogram-Language Models Through a Unified Framework](https://arxiv.org/abs/2505.18847)** - William Han, Chaojing Duan, Zhepeng Cen, Yihang Yao, Xiaoyu Song, Atharva Mhaskar, Dylan Leong, Michael A. Rosenberg, Emerson Liu, Ding Zhao (2025)
- **[Retrieval-Augmented Generation for Electrocardiogram-Language Models](https://arxiv.org/abs/2510.00261)** - Xiaoyu Song, William Han, Tony Chen, Chaojing Duan, Michael A. Rosenberg, Emerson Liu, Ding Zhao (2025)
- **[SensorLM: Learning the Language of Wearable Sensors](https://arxiv.org/abs/2506.09108)** - Yuwei Zhang, Kumar Ayush, Siyuan Qiao, A. Ali Heydari, et al. (2025)
- **[LSM-2: Learning from Incomplete Wearable Sensor Data](https://arxiv.org/abs/2506.05321)** - Maxwell A. Xu, Girish Narayanswamy, Kumar Ayush, Dimitris Spathis, et al. (2025)
- **[PPGFlowECG: Latent Rectified Flow with Cross-Modal Encoding for PPG-Guided ECG Generation and Cardiovascular Disease Detection](https://arxiv.org/abs/2509.19774)** - Xiaocheng Fang, Jiarui Jin, Haoyu Wang, Che Liu, Jieyi Cai, Guangkun Nie, Jun Li, Hongyan Li, Shenda Hong (2025)
- **[MEETI: A Multimodal ECG Dataset from MIMIC-IV-ECG with Signals, Images, Features and Interpretations](https://arxiv.org/abs/2507.15255)** - Deyun Zhang, Xiang Lan, Shijia Geng, Qinghao Zhao, Sumei Fan, Mengling Feng, Shenda Hong (2025)

### ðŸ”’ Privacy
- **[Communication-Efficient Learning of Deep Networks from Decentralized Data (Federated Learning)](https://arxiv.org/abs/1602.05629)** - H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise AgÃ¼era y Arcas (2016)
- **[Privacy and Security Challenges in Large Language Models](https://ieeexplore.ieee.org/abstract/document/10903912)** - Vishal Rathod, Seyedsina Nabavirazavi, Samira Zad, Sundararaja Sitharama Iyengar (2025)
- **[SoK: Security and Privacy Risks of Healthcare AI](https://arxiv.org/abs/2409.07415)** - Yuanhaur Chang, Han Liu, Chenyang Lu, Ning Zhang (2024)

### ðŸ”¬ Multimodal
- **[Zero-Shot Text-to-Image Generation (DALL-E)](https://arxiv.org/abs/2102.12092)** - Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, Ilya Sutskever (2021)
- **[Learning Transferable Visual Models From Natural Language Supervision (CLIP)](https://arxiv.org/abs/2103.00020)** - Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, et al. (2021)
- **[BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://arxiv.org/abs/2201.12086)** - Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi (2022)
- **[Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343)** - Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, Lucas Beyer (2023)
- **[Visual Instruction Tuning (LLaVA)](https://arxiv.org/abs/2304.08485)** - Haotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee (2023)
- **[Med-Flamingo: a Multimodal Medical Few-shot Learner](https://arxiv.org/abs/2307.15189)** - Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, Cyril Zakka, Yash Dalmia, Eduardo Pontes Reis, Pranav Rajpurkar, Jure Leskovec (2023)
- **[CLIMB: Data Foundations for Large Scale Multimodal Clinical Foundation Models](https://arxiv.org/abs/2503.07667)** - Wei Dai, Peilin Chen, Malinda Lu, Daniel Li, Haowen Wei, Hejie Cui, Paul Pu Liang (2025)
- **[Qwen2.5-VL Technical Report](https://arxiv.org/abs/2502.13923)** - Qwen Team, Alibaba (2025)

### 

---

## ðŸ“– AI/ML Knowledge


---

## Courses

- **[Introduction to Deep Learning](https://deeplearning.cs.cmu.edu/F25/index.html)** - CMU 11-785, Fall 2025
- **[Large Language Models: Methods, Analysis, and Applications](https://cmu-llms.org/)** - CMU 11-667/11-867
- **[Advanced Natural Language Processing](https://cmu-l3.github.io/anlp-spring2025/)** - CMU 11-711, Spring 2025
- **[Multimodal Machine Learning](https://cmu-mmml.github.io/)** ([YouTube](https://www.youtube.com/@LPMorency)) - CMU 11-777
- **[How To AI (Almost) Anything](https://mit-mi.github.io/how2ai-course/spring2025/)** - MIT MAS.S60, Spring 2025
- **[Affective Computing and Multimodal Interaction](https://sites.google.com/media.mit.edu/2025acmmi/)** - MIT MAS.S63, Fall 2025

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
